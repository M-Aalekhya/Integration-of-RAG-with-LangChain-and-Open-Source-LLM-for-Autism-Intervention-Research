{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d14e46-e339-4e88-85d9-f2b4180f8674",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9b8bab-d590-4ca7-aaa1-04a43e2ff8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules and libraries\n",
    "\n",
    "import glob\n",
    "from pdf2docx import Converter\n",
    "import docx\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36be8466-202a-44d6-821d-748341152bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for converting pdf to docx\n",
    "\n",
    "def pdf_to_docx(pdf_file):\n",
    "    docx_file = pdf_file[:-4]+\".docx\"\n",
    "    # Create a PDF to DOCX converter object\n",
    "    cv = Converter(pdf_file)\n",
    "    # Convert PDF to DOCX\n",
    "    cv.convert(docx_file, start=0, end=None)\n",
    "    # Close the converter\n",
    "    cv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a042821-c3d9-449f-a901-f8ad3b4d5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pdfs\\15_Nazneen.pdf\n",
      "./pdfs\\1_Ramƒ±rez-Duque_.pdf\n",
      "./pdfs\\22_Ouss_ASD.pdf\n",
      "./pdfs\\Abbas_2018.pdf\n",
      "./pdfs\\Abbas_2020.pdf\n",
      "./pdfs\\Asd_Cry_patterns.pdf\n",
      "./pdfs\\carpenter2020 (1).pdf\n",
      "./pdfs\\Dawson.pdf\n",
      "./pdfs\\LEE.pdf\n",
      "./pdfs\\Patten_Audio.pdf\n",
      "./pdfs\\Qiu.pdf\n",
      "./pdfs\\Tariq2018.pdf\n",
      "./pdfs\\Tariq_2019.pdf\n",
      "./pdfs\\Young_Behavior.pdf\n",
      "./pdfs\\zhao2020.pdf\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob('./pdfs/*.pdf'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a6ae7c-b509-4d2e-9a69-827335374332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start to convert ./pdfs\\1_Ramƒ±rez-Duque_.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] Start to convert ./pdfs\\22_Ouss_ASD.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/7) Page 1\n",
      "[INFO] (2/7) Page 2\n",
      "[INFO] (3/7) Page 3\n",
      "[INFO] (4/7) Page 4\n",
      "[INFO] (5/7) Page 5\n",
      "[INFO] (6/7) Page 6\n",
      "[INFO] (7/7) Page 7\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/7) Page 1\n",
      "[INFO] (2/7) Page 2\n",
      "[INFO] (3/7) Page 3\n",
      "[INFO] (4/7) Page 4\n",
      "[INFO] (5/7) Page 5\n",
      "[INFO] (6/7) Page 6\n",
      "[INFO] (7/7) Page 7\n",
      "[INFO] Terminated in 62.28s.\n",
      "[INFO] Start to convert ./pdfs\\Abbas_2018.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] Terminated in 17.27s.\n",
      "[INFO] Start to convert ./pdfs\\Abbas_2020.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] Terminated in 22.72s.\n",
      "[INFO] Start to convert ./pdfs\\Asd_Cry_patterns.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/21) Page 1\n",
      "[INFO] (2/21) Page 2\n",
      "[INFO] (3/21) Page 3\n",
      "[INFO] (4/21) Page 4\n",
      "[INFO] (5/21) Page 5\n",
      "[INFO] (6/21) Page 6\n",
      "[INFO] (7/21) Page 7\n",
      "[INFO] (8/21) Page 8\n",
      "[INFO] (9/21) Page 9\n",
      "[INFO] (10/21) Page 10\n",
      "[INFO] (11/21) Page 11\n",
      "[INFO] (12/21) Page 12\n",
      "[INFO] (13/21) Page 13\n",
      "[INFO] (14/21) Page 14\n",
      "[INFO] (15/21) Page 15\n",
      "[INFO] (16/21) Page 16\n",
      "[INFO] (17/21) Page 17\n",
      "[INFO] (18/21) Page 18\n",
      "[INFO] (19/21) Page 19\n",
      "[INFO] (20/21) Page 20\n",
      "[INFO] (21/21) Page 21\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/21) Page 1\n",
      "[INFO] (2/21) Page 2\n",
      "[INFO] (3/21) Page 3\n",
      "[INFO] (4/21) Page 4\n",
      "[INFO] (5/21) Page 5\n",
      "[INFO] (6/21) Page 6\n",
      "[INFO] (7/21) Page 7\n",
      "[INFO] (8/21) Page 8\n",
      "[INFO] (9/21) Page 9\n",
      "[INFO] (10/21) Page 10\n",
      "[INFO] (11/21) Page 11\n",
      "[INFO] (12/21) Page 12\n",
      "[INFO] (13/21) Page 13\n",
      "[INFO] (14/21) Page 14\n",
      "[INFO] (15/21) Page 15\n",
      "[INFO] (16/21) Page 16\n",
      "[INFO] (17/21) Page 17\n",
      "[INFO] (18/21) Page 18\n",
      "[INFO] (19/21) Page 19\n",
      "[INFO] (20/21) Page 20\n",
      "[INFO] (21/21) Page 21\n",
      "[INFO] Terminated in 215.73s.\n",
      "[INFO] Start to convert ./pdfs\\carpenter2020 (1).pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/12) Page 1\n",
      "[INFO] (2/12) Page 2\n",
      "[INFO] (3/12) Page 3\n",
      "[INFO] (4/12) Page 4\n",
      "[INFO] (5/12) Page 5\n",
      "[INFO] (6/12) Page 6\n",
      "[INFO] (7/12) Page 7\n",
      "[INFO] (8/12) Page 8\n",
      "[INFO] (9/12) Page 9\n",
      "[INFO] (10/12) Page 10\n",
      "[INFO] (11/12) Page 11\n",
      "[INFO] (12/12) Page 12\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/12) Page 1\n",
      "[INFO] (2/12) Page 2\n",
      "[INFO] (3/12) Page 3\n",
      "[INFO] (4/12) Page 4\n",
      "[INFO] (5/12) Page 5\n",
      "[INFO] (6/12) Page 6\n",
      "[INFO] (7/12) Page 7\n",
      "[INFO] (8/12) Page 8\n",
      "[INFO] (9/12) Page 9\n",
      "[INFO] (10/12) Page 10\n",
      "[INFO] (11/12) Page 11\n",
      "[INFO] (12/12) Page 12\n",
      "[INFO] Terminated in 25.90s.\n",
      "[INFO] Start to convert ./pdfs\\Dawson.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Ignore Line \"n\" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/7) Page 1\n",
      "[INFO] (2/7) Page 2\n",
      "[INFO] (3/7) Page 3\n",
      "[INFO] (4/7) Page 4\n",
      "[INFO] (5/7) Page 5\n",
      "[INFO] (6/7) Page 6\n",
      "[INFO] (7/7) Page 7\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/7) Page 1\n",
      "[INFO] (2/7) Page 2\n",
      "[INFO] (3/7) Page 3\n",
      "[INFO] (4/7) Page 4\n",
      "[INFO] (5/7) Page 5\n",
      "[INFO] (6/7) Page 6\n",
      "[INFO] (7/7) Page 7\n",
      "[INFO] Terminated in 11.32s.\n",
      "[INFO] Start to convert ./pdfs\\LEE.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Ignore Line \" ùíöùëéùë¢ùë•= ùúï(ùëæ2,ùëéùíõ2 + ùíÉ2,ùëé)\" due to overlap\n",
      "[WARNING] Ignore Line \"where ùíöùëüùëíùëê refers to the reconstructed eGeMAPS features, ùíöùëéùë¢ùë• is the auxiliary classification result, \" due to overlap\n",
      "[WARNING] Ignore Line \"N\" due to overlap\n",
      "[WARNING] Ignore Line \"Figure 2. Structure of a joint optimization model of an auto-encoder (AE) and bidirectional long short-\" due to overlap\n",
      "[WARNING] Ignore Line \"term memory (BLSTM). \" due to overlap\n",
      "[WARNING] Ignore Line \"9 of 11\" due to overlap\n",
      "[WARNING] Ignore Line \"Sensors 2020, 20, 6762\" due to overlap\n",
      "[WARNING] Ignore Line \"Figure 3. Two-dimensional scatter plot for (a) eGeMAPS-88, (b) eGeMAPS-54, and (c) the AE \" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/11) Page 1\n",
      "[INFO] (2/11) Page 2\n",
      "[INFO] (3/11) Page 3\n",
      "[INFO] (4/11) Page 4\n",
      "[INFO] (5/11) Page 5\n",
      "[INFO] (6/11) Page 6\n",
      "[INFO] (7/11) Page 7\n",
      "[INFO] (8/11) Page 8\n",
      "[INFO] (9/11) Page 9\n",
      "[INFO] (10/11) Page 10\n",
      "[INFO] (11/11) Page 11\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/11) Page 1\n",
      "[INFO] (2/11) Page 2\n",
      "[INFO] (3/11) Page 3\n",
      "[INFO] (4/11) Page 4\n",
      "[INFO] (5/11) Page 5\n",
      "[INFO] (6/11) Page 6\n",
      "[INFO] (7/11) Page 7\n",
      "[INFO] (8/11) Page 8\n",
      "[INFO] (9/11) Page 9\n",
      "[INFO] (10/11) Page 10\n",
      "[INFO] (11/11) Page 11\n",
      "[INFO] Terminated in 34.69s.\n",
      "[INFO] Start to convert ./pdfs\\Patten_Audio.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/35) Page 1\n",
      "[INFO] (2/35) Page 2\n",
      "[INFO] (3/35) Page 3\n",
      "[INFO] (4/35) Page 4\n",
      "[INFO] (5/35) Page 5\n",
      "[INFO] (6/35) Page 6\n",
      "[INFO] (7/35) Page 7\n",
      "[INFO] (8/35) Page 8\n",
      "[INFO] (9/35) Page 9\n",
      "[INFO] (10/35) Page 10\n",
      "[INFO] (11/35) Page 11\n",
      "[INFO] (12/35) Page 12\n",
      "[INFO] (13/35) Page 13\n",
      "[INFO] (14/35) Page 14\n",
      "[INFO] (15/35) Page 15\n",
      "[INFO] (16/35) Page 16\n",
      "[INFO] (17/35) Page 17\n",
      "[INFO] (18/35) Page 18\n",
      "[INFO] (19/35) Page 19\n",
      "[INFO] (20/35) Page 20\n",
      "[INFO] (21/35) Page 21\n",
      "[INFO] (22/35) Page 22\n",
      "[INFO] (23/35) Page 23\n",
      "[INFO] (24/35) Page 24\n",
      "[INFO] (25/35) Page 25\n",
      "[INFO] (26/35) Page 26\n",
      "[INFO] (27/35) Page 27\n",
      "[INFO] (28/35) Page 28\n",
      "[INFO] (29/35) Page 29\n",
      "[INFO] (30/35) Page 30\n",
      "[INFO] (31/35) Page 31\n",
      "[INFO] (32/35) Page 32\n",
      "[INFO] (33/35) Page 33\n",
      "[INFO] (34/35) Page 34\n",
      "[INFO] (35/35) Page 35\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/35) Page 1\n",
      "[INFO] (2/35) Page 2\n",
      "[INFO] (3/35) Page 3\n",
      "[INFO] (4/35) Page 4\n",
      "[INFO] (5/35) Page 5\n",
      "[INFO] (6/35) Page 6\n",
      "[INFO] (7/35) Page 7\n",
      "[INFO] (8/35) Page 8\n",
      "[INFO] (9/35) Page 9\n",
      "[INFO] (10/35) Page 10\n",
      "[INFO] (11/35) Page 11\n",
      "[INFO] (12/35) Page 12\n",
      "[INFO] (13/35) Page 13\n",
      "[INFO] (14/35) Page 14\n",
      "[INFO] (15/35) Page 15\n",
      "[INFO] (16/35) Page 16\n",
      "[INFO] (17/35) Page 17\n",
      "[INFO] (18/35) Page 18\n",
      "[INFO] (19/35) Page 19\n",
      "[INFO] (20/35) Page 20\n",
      "[INFO] (21/35) Page 21\n",
      "[INFO] (22/35) Page 22\n",
      "[INFO] (23/35) Page 23\n",
      "[INFO] (24/35) Page 24\n",
      "[INFO] (25/35) Page 25\n",
      "[INFO] (26/35) Page 26\n",
      "[INFO] (27/35) Page 27\n",
      "[INFO] (28/35) Page 28\n",
      "[INFO] (29/35) Page 29\n",
      "[INFO] (30/35) Page 30\n",
      "[INFO] (31/35) Page 31\n",
      "[INFO] (32/35) Page 32\n",
      "[INFO] (33/35) Page 33\n",
      "[INFO] (34/35) Page 34\n",
      "[INFO] (35/35) Page 35\n",
      "[INFO] Terminated in 16.11s.\n",
      "[INFO] Start to convert ./pdfs\\Qiu.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/9) Page 1\n",
      "[INFO] (2/9) Page 2\n",
      "[INFO] (3/9) Page 3\n",
      "[INFO] (4/9) Page 4\n",
      "[INFO] (5/9) Page 5\n",
      "[INFO] (6/9) Page 6\n",
      "[INFO] (7/9) Page 7\n",
      "[INFO] (8/9) Page 8\n",
      "[INFO] (9/9) Page 9\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/9) Page 1\n",
      "[INFO] (2/9) Page 2\n",
      "[INFO] (3/9) Page 3\n",
      "[INFO] (4/9) Page 4\n",
      "[INFO] (5/9) Page 5\n",
      "[INFO] (6/9) Page 6\n",
      "[INFO] (7/9) Page 7\n",
      "[INFO] (8/9) Page 8\n",
      "[INFO] (9/9) Page 9\n",
      "[INFO] Terminated in 30.26s.\n",
      "[INFO] Start to convert ./pdfs\\Tariq2018.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/20) Page 1\n",
      "[INFO] (2/20) Page 2\n",
      "[INFO] (3/20) Page 3\n",
      "[INFO] (4/20) Page 4\n",
      "[INFO] (5/20) Page 5\n",
      "[INFO] (6/20) Page 6\n",
      "[INFO] (7/20) Page 7\n",
      "[INFO] (8/20) Page 8\n",
      "[INFO] (9/20) Page 9\n",
      "[INFO] (10/20) Page 10\n",
      "[INFO] (11/20) Page 11\n",
      "[INFO] (12/20) Page 12\n",
      "[INFO] (13/20) Page 13\n",
      "[INFO] (14/20) Page 14\n",
      "[INFO] (15/20) Page 15\n",
      "[INFO] (16/20) Page 16\n",
      "[INFO] (17/20) Page 17\n",
      "[INFO] (18/20) Page 18\n",
      "[INFO] (19/20) Page 19\n",
      "[INFO] (20/20) Page 20\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/20) Page 1\n",
      "[INFO] (2/20) Page 2\n",
      "[INFO] (3/20) Page 3\n",
      "[INFO] (4/20) Page 4\n",
      "[INFO] (5/20) Page 5\n",
      "[INFO] (6/20) Page 6\n",
      "[INFO] (7/20) Page 7\n",
      "[INFO] (8/20) Page 8\n",
      "[INFO] (9/20) Page 9\n",
      "[INFO] (10/20) Page 10\n",
      "[INFO] (11/20) Page 11\n",
      "[INFO] (12/20) Page 12\n",
      "[INFO] (13/20) Page 13\n",
      "[INFO] (14/20) Page 14\n",
      "[INFO] (15/20) Page 15\n",
      "[INFO] (16/20) Page 16\n",
      "[INFO] (17/20) Page 17\n",
      "[INFO] (18/20) Page 18\n",
      "[INFO] (19/20) Page 19\n",
      "[INFO] (20/20) Page 20\n",
      "[INFO] Terminated in 82.30s.\n",
      "[INFO] Start to convert ./pdfs\\Young_Behavior.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/15) Page 1\n",
      "[INFO] (2/15) Page 2\n",
      "[INFO] (3/15) Page 3\n",
      "[INFO] (4/15) Page 4\n",
      "[INFO] (5/15) Page 5\n",
      "[INFO] (6/15) Page 6\n",
      "[INFO] (7/15) Page 7\n",
      "[INFO] (8/15) Page 8\n",
      "[INFO] (9/15) Page 9\n",
      "[INFO] (10/15) Page 10\n",
      "[INFO] (11/15) Page 11\n",
      "[INFO] (12/15) Page 12\n",
      "[INFO] (13/15) Page 13\n",
      "[INFO] (14/15) Page 14\n",
      "[INFO] (15/15) Page 15\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/15) Page 1\n",
      "[INFO] (2/15) Page 2\n",
      "[INFO] (3/15) Page 3\n",
      "[INFO] (4/15) Page 4\n",
      "[INFO] (5/15) Page 5\n",
      "[INFO] (6/15) Page 6\n",
      "[INFO] (7/15) Page 7\n",
      "[INFO] (8/15) Page 8\n",
      "[INFO] (9/15) Page 9\n",
      "[INFO] (10/15) Page 10\n",
      "[INFO] (11/15) Page 11\n",
      "[INFO] (12/15) Page 12\n",
      "[INFO] (13/15) Page 13\n",
      "[INFO] (14/15) Page 14\n",
      "[INFO] (15/15) Page 15\n",
      "[INFO] Terminated in 9.87s.\n",
      "[INFO] Start to convert ./pdfs\\zhao2020.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/19) Page 1\n",
      "[INFO] (2/19) Page 2\n",
      "[INFO] (3/19) Page 3\n",
      "[INFO] (4/19) Page 4\n",
      "[INFO] (5/19) Page 5\n",
      "[INFO] (6/19) Page 6\n",
      "[INFO] (7/19) Page 7\n",
      "[INFO] (8/19) Page 8\n",
      "[INFO] (9/19) Page 9\n",
      "[INFO] (10/19) Page 10\n",
      "[INFO] (11/19) Page 11\n",
      "[INFO] (12/19) Page 12\n",
      "[INFO] (13/19) Page 13\n",
      "[INFO] (14/19) Page 14\n",
      "[INFO] (15/19) Page 15\n",
      "[INFO] (16/19) Page 16\n",
      "[INFO] (17/19) Page 17\n",
      "[INFO] (18/19) Page 18\n",
      "[INFO] (19/19) Page 19\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/19) Page 1\n",
      "[INFO] (2/19) Page 2\n",
      "[INFO] (3/19) Page 3\n",
      "[INFO] (4/19) Page 4\n",
      "[INFO] (5/19) Page 5\n",
      "[INFO] (6/19) Page 6\n",
      "[INFO] (7/19) Page 7\n",
      "[INFO] (8/19) Page 8\n",
      "[INFO] (9/19) Page 9\n",
      "[INFO] (10/19) Page 10\n",
      "[INFO] (11/19) Page 11\n",
      "[INFO] (12/19) Page 12\n",
      "[INFO] (13/19) Page 13\n",
      "[INFO] (14/19) Page 14\n",
      "[INFO] (15/19) Page 15\n",
      "[INFO] (16/19) Page 16\n",
      "[INFO] (17/19) Page 17\n",
      "[INFO] (18/19) Page 18\n",
      "[INFO] (19/19) Page 19\n",
      "[INFO] Terminated in 36.96s.\n"
     ]
    }
   ],
   "source": [
    "#Converting pdf files to docx files\n",
    "\n",
    "for file in glob.glob('./pdfs/*.pdf')[1:-3]:\n",
    "    try:\n",
    "        pdf_to_docx(file)\n",
    "    except Exception:\n",
    "        print('')\n",
    "for file in glob.glob('./pdfs/*.pdf')[-2:]:\n",
    "    try:\n",
    "        pdf_to_docx(file)\n",
    "    except Exception:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcbe2dcf-29af-442f-bc96-438d35cefc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for converting docx file to txt\n",
    "\n",
    "def write_to_txt_file(file_name, data_list):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        for item in data_list:\n",
    "            file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a305da-48b0-475e-88af-b1c9e6b87136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing figures, tables and in-text citations from the papers\n",
    "\n",
    "def table_removal(doc_file):\n",
    "    content = []\n",
    "    doc = docx.Document(doc_file)\n",
    "    patterns = [r'\\[[0-9]+\\]', r'\\[[0-9]+,\\s*[0-9]+\\]', r'\\[[0-9]+-[0-9]+\\]', r'\\[[0-9]+(,\\s*[0-9]+)+\\]']\n",
    "    for paragraph in doc.paragraphs:\n",
    "        para = paragraph.text\n",
    "        if 'References' in para:\n",
    "            break\n",
    "        else:\n",
    "            for pattern in patterns:\n",
    "                para = re.sub(pattern, '', para)\n",
    "            content.append(para)\n",
    "    txt_file = doc_file[:-5]+\".txt\"\n",
    "    write_to_txt_file(txt_file, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfb37f6-d669-41d2-b017-341cccdcdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing docx files in a separate folder\n",
    "\n",
    "if os.path.exists('./pdftodocx'):\n",
    "    shutil.rmtree('./pdftodocx')\n",
    "    os.mkdir('./pdftodocx')\n",
    "else:\n",
    "    os.mkdir('./pdftodocx')\n",
    "    \n",
    "for file in glob.glob('./pdfs/*.docx'):\n",
    "    shutil.move(file, './pdftodocx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f086c1-5175-4ccd-b503-08c41c1f5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing txt files in a separate folder\n",
    "\n",
    "for file in glob.glob('./pdftodocx/*.docx'):\n",
    "    table_removal(file)\n",
    "\n",
    "if os.path.exists('./docxtotxt'):\n",
    "    shutil.rmtree('./docxtotxt')\n",
    "    os.mkdir('./docxtotxt')\n",
    "else:\n",
    "    os.mkdir('./docxtotxt')\n",
    "    \n",
    "for file in glob.glob('./pdftodocx/*.txt'):\n",
    "    shutil.move(file, './docxtotxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038c4b4-2e40-4463-bd65-72b8ac15e07b",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb11182e-3eae-4e1d-9d5b-08d592d2129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing modules and libraries\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcb3803-43a1-4062-83f3-f7e5e25f81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcaf6342-c87f-4ed1-8956-cef72371cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the file ./docxtotxt\\15_Nazneen.txt\n",
      "Cleaning the file ./docxtotxt\\1_Ramƒ±rez-Duque_.txt\n",
      "Cleaning the file ./docxtotxt\\22_Ouss_ASD.txt\n",
      "Cleaning the file ./docxtotxt\\Abbas_2018.txt\n",
      "Cleaning the file ./docxtotxt\\Abbas_2020.txt\n",
      "Cleaning the file ./docxtotxt\\Asd_Cry_patterns.txt\n",
      "Cleaning the file ./docxtotxt\\carpenter2020 (1).txt\n",
      "Cleaning the file ./docxtotxt\\Dawson.txt\n",
      "Cleaning the file ./docxtotxt\\LEE.txt\n",
      "Cleaning the file ./docxtotxt\\Patten_Audio.txt\n",
      "Cleaning the file ./docxtotxt\\Qiu.txt\n",
      "Cleaning the file ./docxtotxt\\Tariq2018.txt\n",
      "Cleaning the file ./docxtotxt\\Tariq_2019.txt\n",
      "Cleaning the file ./docxtotxt\\Young_Behavior.txt\n",
      "Cleaning the file ./docxtotxt\\zhao2020.txt\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words, stemming, and lemmatizing from the txt files\n",
    "\n",
    "vector_dataset = []\n",
    "for file in glob.glob('./docxtotxt/*.txt'):\n",
    "    print(f'Cleaning the file {file}')\n",
    "    final_tokenids = []\n",
    "    with open(file,'r', encoding=\"utf8\") as f:\n",
    "        tokens = word_tokenize(f.read())\n",
    "        for token in tokens:\n",
    "            stemmed = stemmer.stem(token)\n",
    "            lemmatized = lemmatizer.lemmatize(stemmed)\n",
    "            if lemmatized not in stop_words:\n",
    "                final_tokenids.append(lemmatized)\n",
    "    vector_dataset.append(\" \".join(final_tokenids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f342cbc-fde6-44a8-96b9-48c928a99a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(vector_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a265195-d096-46d0-a2f4-5f6a9a331583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a vectorizer and storing vector representation of each clean file in a vector database\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_database = vectorizer.fit_transform(vector_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a44eb90-d090-43f0-b420-b470e678706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 1203)\t0.004198583023602918\n",
      "  (1, 4124)\t0.00463169509425807\n",
      "  (1, 1483)\t0.005190073668750274\n",
      "  (1, 5)\t0.00463169509425807\n",
      "  (1, 1862)\t0.005977064068055437\n",
      "  (1, 943)\t0.005977064068055437\n",
      "  (1, 879)\t0.005977064068055437\n",
      "  (1, 4218)\t0.005190073668750274\n",
      "  (1, 4844)\t0.005977064068055437\n",
      "  (1, 3296)\t0.005977064068055437\n",
      "  (1, 3086)\t0.005977064068055437\n",
      "  (1, 604)\t0.005977064068055437\n",
      "  (1, 1349)\t0.010636514493837533\n",
      "  (1, 600)\t0.005977064068055437\n",
      "  (1, 1252)\t0.005977064068055437\n",
      "  (1, 3946)\t0.005977064068055437\n",
      "  (1, 3839)\t0.005977064068055437\n",
      "  (1, 3461)\t0.0035455048312791775\n",
      "  (1, 2563)\t0.005977064068055437\n",
      "  (1, 717)\t0.005190073668750274\n",
      "  (1, 560)\t0.005190073668750274\n",
      "  (1, 2578)\t0.005977064068055437\n",
      "  (1, 2033)\t0.005190073668750274\n",
      "  (1, 457)\t0.003057714295647743\n",
      "  (1, 1980)\t0.005977064068055437\n",
      "  :\t:\n",
      "  (14, 3278)\t0.0018873283965060482\n",
      "  (14, 1447)\t0.07171847906722983\n",
      "  (14, 3281)\t0.0028190880059670675\n",
      "  (14, 1435)\t0.0018873283965060482\n",
      "  (14, 1584)\t0.01608574464343564\n",
      "  (14, 1915)\t0.0021439890918089678\n",
      "  (14, 4251)\t0.0021439890918089678\n",
      "  (14, 3268)\t0.032980783083413456\n",
      "  (14, 504)\t0.009790217052635003\n",
      "  (14, 3005)\t0.0028190880059670675\n",
      "  (14, 435)\t0.0028190880059670675\n",
      "  (14, 3509)\t0.0024475542631587507\n",
      "  (14, 129)\t0.0018873283965060482\n",
      "  (14, 149)\t0.01602204050414623\n",
      "  (14, 3599)\t0.00402143616085891\n",
      "  (14, 3597)\t0.004895108526317501\n",
      "  (14, 640)\t0.02160986087814677\n",
      "  (14, 754)\t0.018873283965060484\n",
      "  (14, 1450)\t0.03774656793012097\n",
      "  (14, 1492)\t0.01132397037903629\n",
      "  (14, 4081)\t0.0037746567930120965\n",
      "  (14, 696)\t0.15098627172048387\n",
      "  (14, 37)\t0.013211298775542337\n",
      "  (14, 4265)\t0.16479813089978979\n",
      "  (14, 2363)\t0.018008217398455643\n"
     ]
    }
   ],
   "source": [
    "# Vector database\n",
    "\n",
    "print(tfidf_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdac26f-153d-44dd-9766-ab23db7794de",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e88fcf1-0149-4d6f-b14d-92dff8bc2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "#importing modules and libraries\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1e148c-77ef-48f1-b7f6-c9eea7440c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the variety of Multimodal and Multi-modular AI Approaches to Streamline Autism Diagnosis in Young Children',\n",
       " 'What is Autism Spectrum Disorder, how it is caysed?',\n",
       " 'What is the cure of Autism Spectrum Disorder',\n",
       " 'What are Stereotypical and maladaptive behaviors in Autism Spectrum, how are these detected and managed',\n",
       " 'How relevant is eye contact and how it can be used to detect Autism',\n",
       " 'How can cross country trials help in development of Machine learning based Multimodal solutions ',\n",
       " 'How early infants cry can help in the early detection of Autism ',\n",
       " 'What are various methods to detect  Atypical Pattern of Facial expression in Children ',\n",
       " 'What kind of facial expressions can be used to detect Autism Disorder in children',\n",
       " 'What are methods to detect Autism from home videos ',\n",
       " 'What is Still-Face Paradigm in Early Screening for High-Risk Autism Spectrum Disorder',\n",
       " 'What is West Syndrome? ',\n",
       " 'What is the utility of Behavior and interaction imaging at 9 months of age predict autism/intellectual disability in high-risk infants with West syndrome']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and storing the 13 questions from the csv file\n",
    "\n",
    "questions = pd.read_csv(\"Query Questions - Sheet1.csv\")\n",
    "queries = list(questions.iloc[:, 1].values)\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b90c7f-fddb-44a5-a6cb-156a04905662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  4  3  7 10] What are the variety of Multimodal and Multi-modular AI Approaches to Streamline Autism Diagnosis in Young Children\n",
      "[11  3  4 14 10] What is Autism Spectrum Disorder, how it is caysed?\n",
      "[11  3  4 14 10] What is the cure of Autism Spectrum Disorder\n",
      "[11  7  3 14  4] What are Stereotypical and maladaptive behaviors in Autism Spectrum, how are these detected and managed\n",
      "[10  3 11  7  1] How relevant is eye contact and how it can be used to detect Autism\n",
      "[3 8 1 6 4] How can cross country trials help in development of Machine learning based Multimodal solutions \n",
      "[11  3 14  4  5] How early infants cry can help in the early detection of Autism \n",
      "[14  6  1  7 11] What are various methods to detect  Atypical Pattern of Facial expression in Children \n",
      "[14  6  3 11  7] What kind of facial expressions can be used to detect Autism Disorder in children\n",
      "[11  3 14  4  7] What are methods to detect Autism from home videos \n",
      "[10 11  3 14  1] What is Still-Face Paradigm in Early Screening for High-Risk Autism Spectrum Disorder\n",
      "[ 2 10  9 14 13] What is West Syndrome? \n",
      "[ 3  2  4 11 10] What is the utility of Behavior and interaction imaging at 9 months of age predict autism/intellectual disability in high-risk infants with West syndrome\n"
     ]
    }
   ],
   "source": [
    "# Converting each query into vector, then comparing with vector database using cosine_similarity to find the top 5 most similar research findings among the papers \n",
    "# printing the file index along with respective query \n",
    "\n",
    "k = 5\n",
    "query_top_5 = []\n",
    "for query in queries:\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    query_similarities = cosine_similarity(query_vector, tfidf_database)\n",
    "    top_k_indices = query_similarities.argsort()[0][-k:][::-1]\n",
    "    print(top_k_indices, query)\n",
    "    query_top_5.append(top_k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b58d8a9-4275-4863-95b6-9016764b52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd4ff9-b492-4031-8f4a-5807b174cd90",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cbd93b5-193a-46fc-bc82-c3002f94bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules and libraries\n",
    "\n",
    "from langchain.chains.summarize import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a9b9f3e-c173-48a2-b658-077819ec308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a summarizer using LLM OpenAI\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=\"Please provide a concise summary of the following documents:\\n\\n{text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "llm = OpenAI(temperature=0.2)\n",
    "summarizer = LLMChain(llm=llm, prompt=summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e04dc670-ce98-4669-a2ac-a4cea8a206f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[INFO] Retrying request to /completions in 0.825213 seconds\n",
      "[INFO] HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[INFO] Retrying request to /completions in 1.828508 seconds\n",
      "[INFO] HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     document \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./docxtotxt/*.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m     documents\u001b[38;5;241m.\u001b[39mappend(document)\n\u001b[1;32m---> 10\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarizer\u001b[38;5;241m.\u001b[39mrun(documents)\n\u001b[0;32m     11\u001b[0m summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:569\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    570\u001b[0m         _output_key\n\u001b[0;32m    571\u001b[0m     ]\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    575\u001b[0m         _output_key\n\u001b[0;32m    576\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    376\u001b[0m }\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    379\u001b[0m     inputs,\n\u001b[0;32m    380\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    381\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    382\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    383\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    116\u001b[0m         prompts,\n\u001b[0;32m    117\u001b[0m         stop,\n\u001b[0;32m    118\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    124\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:597\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    591\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    595\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    596\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:767\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    754\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    755\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m         )\n\u001b[0;32m    766\u001b[0m     ]\n\u001b[1;32m--> 767\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    768\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    769\u001b[0m     )\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:634\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    633\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:621\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    613\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    618\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    620\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 621\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    622\u001b[0m                 prompts,\n\u001b[0;32m    623\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    625\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    627\u001b[0m             )\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    630\u001b[0m         )\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\openai.py:460\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    449\u001b[0m         {\n\u001b[0;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m         }\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     response \u001b[38;5;241m=\u001b[39m completion_with_retry(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;28mself\u001b[39m, prompt\u001b[38;5;241m=\u001b[39m_prompts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    117\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\completions.py:516\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    518\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    519\u001b[0m             {\n\u001b[0;32m    520\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    521\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    522\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_of,\n\u001b[0;32m    523\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mecho\u001b[39m\u001b[38;5;124m\"\u001b[39m: echo,\n\u001b[0;32m    524\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    525\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    526\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    527\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    528\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    529\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    530\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    531\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    532\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    533\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuffix\u001b[39m\u001b[38;5;124m\"\u001b[39m: suffix,\n\u001b[0;32m    534\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    535\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    536\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    537\u001b[0m             },\n\u001b[0;32m    538\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    539\u001b[0m         ),\n\u001b[0;32m    540\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    541\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    542\u001b[0m         ),\n\u001b[0;32m    543\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mCompletion,\n\u001b[0;32m    544\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    545\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[Completion],\n\u001b[0;32m    546\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1212\u001b[0m     )\n\u001b[1;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    903\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    904\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    905\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    906\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    907\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    908\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    977\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    979\u001b[0m         options,\n\u001b[0;32m    980\u001b[0m         cast_to,\n\u001b[0;32m    981\u001b[0m         retries,\n\u001b[0;32m    982\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    983\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    984\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1028\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1029\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1030\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1031\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1032\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    977\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    979\u001b[0m         options,\n\u001b[0;32m    980\u001b[0m         cast_to,\n\u001b[0;32m    981\u001b[0m         retries,\n\u001b[0;32m    982\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    983\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    984\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1028\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1029\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1030\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1031\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1032\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1001\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Finding summaries for each query from the top 5 research findings of each query respectively and storing them in a list in order.\n",
    "# Summary for a query can be retrieved from the list summaries if given the correct index number of the required query as stored in the list queries.\n",
    "\n",
    "summaries = []\n",
    "for query in query_top_5:\n",
    "    documents = []\n",
    "    for i in query:\n",
    "        document = glob.glob('./docxtotxt/*.txt')[i-1]\n",
    "        documents.append(document)\n",
    "    summary = summarizer.run(documents)\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24677a8c-8141-41eb-a2e2-b1f742f6cdb0",
   "metadata": {},
   "source": [
    "'error': {'message': 'You exceeded your current quota, please check your plan and billing details. \n",
    "I used free OpenAI API which is not providing required quota, code is correct, will be running correctly with OpenAI paid version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
